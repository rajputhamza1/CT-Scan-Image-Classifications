{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b07823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fd1b0",
   "metadata": {},
   "source": [
    "# Set the random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b179bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f96af",
   "metadata": {},
   "source": [
    "# Set the path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79dbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\rajpu\\\\Documents\\\\Python Scripts\\\\COVID CT\\\\Capstone_project-20230702T085249Z-001\\\\Capstone_project'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057a057",
   "metadata": {},
   "source": [
    "# Set the desired image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e5252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ee8b3",
   "metadata": {},
   "source": [
    "\n",
    "# Step 1: Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be59ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Load COVID-19 positive images\n",
    "    covid_dir = os.path.join(data_dir, 'COVID')\n",
    "    covid_images = []\n",
    "    for filename in os.listdir(covid_dir):\n",
    "        img = cv2.imread(os.path.join(covid_dir, filename))\n",
    "        img = cv2.resize(img, image_size)\n",
    "        covid_images.append(img)\n",
    "\n",
    "    # Load non-infected images\n",
    "    non_infected_dir = os.path.join(data_dir, 'non-COVID')\n",
    "    non_infected_images = []\n",
    "    for filename in os.listdir(non_infected_dir):\n",
    "        img = cv2.imread(os.path.join(non_infected_dir, filename))\n",
    "        img = cv2.resize(img, image_size)\n",
    "        non_infected_images.append(img)\n",
    "\n",
    "    # Create labels (1 for COVID-19 positive, 0 for non-infected)\n",
    "    labels = [1] * len(covid_images) + [0] * len(non_infected_images)\n",
    "\n",
    "    # Combine images and labels\n",
    "    images = covid_images + non_infected_images\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074340a8",
   "metadata": {},
   "source": [
    "# Step 2: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b745d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_augmentation(X_train):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    datagen.fit(X_train)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2852d3",
   "metadata": {},
   "source": [
    "# Step 3: Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6ee94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_val, y_val):\n",
    "    # Load pre-trained ResNet50 model\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Set up data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    batch_size = 32\n",
    "\n",
    "    # Create data generator from training set\n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "    # Set up early stopping and model checkpoint callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_generator, steps_per_epoch=len(X_train) // batch_size, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd08537",
   "metadata": {},
   "source": [
    "# Step 5: Perform predictions and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a6a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Perform predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).flatten()\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1)\n",
    "    recall = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_test == 1)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    # Print performance metrics\n",
    "    print('Accuracy:', accuracy*100)\n",
    "    print('Precision:', precision*100)\n",
    "    print('Recall:', recall*100)\n",
    "    print('F1-Score:', f1_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702e017",
   "metadata": {},
   "source": [
    "## Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ecf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d7057",
   "metadata": {},
   "source": [
    "## Split the dataset into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f11c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b4d65",
   "metadata": {},
   "source": [
    "## Apply data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e795f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = apply_data_augmentation(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e88c2c",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126c6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 121s 2s/step - loss: 6.1144 - accuracy: 0.5150 - val_loss: 0.6414 - val_accuracy: 0.5038\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.5854 - accuracy: 0.6752 - val_loss: 0.5528 - val_accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 119s 2s/step - loss: 0.5463 - accuracy: 0.8268 - val_loss: 0.5549 - val_accuracy: 0.8184\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 125s 3s/step - loss: 0.5064 - accuracy: 0.8569 - val_loss: 0.4810 - val_accuracy: 0.8721\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 125s 3s/step - loss: 0.4826 - accuracy: 0.8680 - val_loss: 0.4712 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 125s 3s/step - loss: 0.4629 - accuracy: 0.8745 - val_loss: 0.4704 - val_accuracy: 0.8696\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 121s 3s/step - loss: 0.4827 - accuracy: 0.8621 - val_loss: 0.5032 - val_accuracy: 0.8133\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 120s 3s/step - loss: 0.4543 - accuracy: 0.8725 - val_loss: 0.4299 - val_accuracy: 0.8875\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 113s 2s/step - loss: 0.4296 - accuracy: 0.8856 - val_loss: 0.4728 - val_accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 115s 2s/step - loss: 0.4151 - accuracy: 0.9052 - val_loss: 0.3957 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "model = build_and_train_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca55f831",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba690b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 27s 2s/step\n",
      "Accuracy: 91.00204498977506\n",
      "Precision: 89.32806324110672\n",
      "Recall: 93.00411522633745\n",
      "F1-Score: 91.12903225806451\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
